{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "mpl.rcParams['lines.linewidth']=2.0\n",
    "mpl.rcParams['xtick.labelsize']=13\n",
    "mpl.rcParams['ytick.labelsize']=13\n",
    "mpl.rcParams['axes.labelsize']=15\n",
    "mpl.rcParams['axes.labelweight']='heavy'\n",
    "mpl.rcParams['axes.titlesize']=18\n",
    "mpl.rcParams['axes.titleweight']='heavy'\n",
    "mpl.rcParams['legend.fontsize']=12\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/peter/Documents/data_projects/adfraud\n"
     ]
    }
   ],
   "source": [
    "src_dir = os.path.join(os.path.dirname(os.getcwd()))\n",
    "print(src_dir)\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from adfraud import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.dirname(os.getcwd()),'data')\n",
    "\n",
    "data_filename = 'train_sample.csv'\n",
    "data_location = os.path.join(data_dir,data_filename)\n",
    "ad_data = pd.read_csv(data_location)\n",
    "#feats_df  = ad_data[['ip','app','channel']]\n",
    "#labels = ad_data['is_attributed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ad_data['click_time'] = pd.to_datetime(ad_data['click_time'],format='%Y-%m-%d %H:%M:%S')\n",
    "ad_data['click_time'] = ad_data['click_time'].dt.hour \n",
    "\n",
    "feats_df = ad_data[['ip','app','channel','click_time','os','device']]\n",
    "labels   = ad_data['is_attributed'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_splitter = StratifiedShuffleSplit(n_splits=1,test_size=0.1,random_state=42)\n",
    "split = train_test_splitter.split(np.zeros((len(labels),)),labels)\n",
    "train_inds,test_inds = next(split)\n",
    "x_train = feats_df.iloc[train_inds]\n",
    "y_train = labels[train_inds]\n",
    "x_test  = feats_df.iloc[test_inds]\n",
    "y_test  = labels[test_inds] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'forest__n_estimators':[50],\n",
    "    'forest__max_depth': [10],\n",
    "    'forest__class_weight': [\n",
    "                           {0:0.001,1:0.999}],\n",
    "    'hash__n_components': [50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50, score=0.921, total=  54.4s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   54.4s remaining:    0.0s\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50, score=0.970, total=  54.2s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50, score=0.895, total=  54.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.7min finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50, score=0.904, total=  54.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   54.9s remaining:    0.0s\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50, score=0.931, total=  54.8s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=50, score=0.854, total=  55.1s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "model1 = models.HashForest(['ip','app','channel'],['app','channel'])\n",
    "model1.train_CV(x_train,y_train,param_grid,n_splits=3)\n",
    "auc1 = model1.test_auc(x_test,y_test)\n",
    "\n",
    "model2 = models.HashForest(['ip','app','channel','click_time'],['app','channel','click_time'])\n",
    "model2.train_CV(x_train,y_train,param_grid,n_splits=3)\n",
    "auc2 = model2.test_auc(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9614744346780202 0.9283874650827337\n",
      "0.9289746246758085\n"
     ]
    }
   ],
   "source": [
    "auc2 = model2.test_auc(x_test,y_test)\n",
    "print(auc1,auc2)\n",
    "print(model1.train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
