{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test adfraud/models.py on data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- import useful packages ------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- plotting imports and setup --------------\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "# mpl.rcParams['lines.linewidth']=2.0\n",
    "# mpl.rcParams['xtick.labelsize']=13\n",
    "# mpl.rcParams['ytick.labelsize']=13\n",
    "# mpl.rcParams['axes.labelsize']=15\n",
    "# mpl.rcParams['axes.labelweight']='heavy'\n",
    "# mpl.rcParams['axes.titlesize']=18\n",
    "# mpl.rcParams['axes.titleweight']='heavy'\n",
    "# mpl.rcParams['legend.fontsize']=12\n",
    "\n",
    "# --------------- ML imports -------------------------\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "# ---------- filesystem imports -----------------------\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import own modules from adfraud ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from adfraud import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load in the data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.dirname(os.getcwd()),'data')\n",
    "\n",
    "data_filename = 'train_sample.csv'\n",
    "data_location = os.path.join(data_dir,data_filename)\n",
    "ad_data = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### process the data ####\n",
    "\n",
    " - change 'click time' field into datetime format and only keep the hour\n",
    " - split data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ad_data['click_time'] = pd.to_datetime(ad_data['click_time'],format='%Y-%m-%d %H:%M:%S')\n",
    "ad_data['click_time'] = ad_data['click_time'].dt.hour \n",
    "\n",
    "feats_df = ad_data[['ip','app','channel','click_time','os','device']]\n",
    "labels   = ad_data['is_attributed'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data into train and test sets ####\n",
    "\n",
    "Since the data is heavily imblanced - use a Stratified split - which keeps the number of minority class cases to be the same fraction of the data in both sets\n",
    "\n",
    "keep 10% of data for testing. Note that in cross validation of models, the training data will be further split into training and validation sets (again with Stratified split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_splitter = StratifiedShuffleSplit(n_splits=1,test_size=0.8,random_state=42)\n",
    "split = train_test_splitter.split(np.zeros((len(labels),)),labels)\n",
    "train_inds,test_inds = next(split)\n",
    "x_train = feats_df.iloc[train_inds]\n",
    "y_train = labels[train_inds]\n",
    "x_test  = feats_df.iloc[test_inds]\n",
    "y_test  = labels[test_inds] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up a parameter grid to search over for optimal Hyperparameters ####\n",
    "\n",
    "\n",
    "note that ideally would do a rough search followed by a finer search in the vicinity of the best point in the parameter space.\n",
    "Alse note that a random search may perform better than grid search.\n",
    "\n",
    "Above to be considered for further development of solution to problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'forest__n_estimators':[50],\n",
    "    'forest__max_depth': [10],\n",
    "    'forest__class_weight': [\n",
    "                           {0:0.001,1:0.999}\n",
    "                            ],\n",
    "    'hash__n_components': [40]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define models using models.py #####\n",
    "\n",
    "Here define two different models, both using models.HashForest() which implements a model (pipeline) for the hashing trick on chosen features, and then applies a random forest to the hashed data.\n",
    "\n",
    "Below, initialize two different models - looking at different sets of features, in the second case we also include the 'click_time' feature column - and it is also hashed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include ip,app,channel in model - hash only app,channel\n",
    "model_ip_app_chan      = models.HashForest(['ip','app','channel'],['app','channel'])\n",
    "# as above but alos hash the ip (hash components will be same though, so expect worse performance)\n",
    "#model_iphash_app_chan  = models.HashForest(['ip','app','channel'],['ip','app','channel'])\n",
    "# here include ip,app,channel,click_time and hash all except ip\n",
    "model_ip_app_chan_time = models.HashForest(['ip','app','channel','click_time'],['app','channel','click_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train the models and find the Area Under the ROC ####\n",
    "\n",
    "note that inside HashForest, the grid search cross validation is perfomred by scoring on AUC - as this is what we wish to optimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40, score=0.868, total=  11.7s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.7s remaining:    0.0s\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40, score=0.942, total=  11.7s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   23.4s remaining:    0.0s\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40, score=0.947, total=  11.7s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   35.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   35.1s finished\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40, score=0.839, total=  12.6s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.6s remaining:    0.0s\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40, score=0.898, total=  13.9s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   26.5s remaining:    0.0s\n",
      "[CV] forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40 \n",
      "[CV]  forest__class_weight={0: 0.001, 1: 0.999}, forest__max_depth=10, forest__n_estimators=50, hash__n_components=40, score=0.840, total=  13.5s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   40.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   40.0s finished\n"
     ]
    }
   ],
   "source": [
    "mods = [model_ip_app_chan,model_ip_app_chan_time]\n",
    "auc = []\n",
    "for m in mods:\n",
    "    m.train_CV(x_train,y_train,param_grid,n_splits=3)\n",
    "    auc.append(m.test_auc(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See how the models performed ####\n",
    "\n",
    " - We can check the area under the (roc) curve on the test set\n",
    " - compare that to the perfomrance on the training set (for the optimal hyperparams)\n",
    " - we can see which hyperparams were selected in validation\n",
    " - see auc score for each model during validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8840836460640263, 0.8609488027570416]\n",
      "[0.918812698942992, 0.8589047579275592]\n",
      "[{'forest__class_weight': {0: 0.001, 1: 0.999}, 'forest__max_depth': 10, 'forest__n_estimators': 50, 'hash__n_components': 40}, {'forest__class_weight': {0: 0.001, 1: 0.999}, 'forest__max_depth': 10, 'forest__n_estimators': 50, 'hash__n_components': 40}]\n",
      "[array([0.9188127]), array([0.85890476])]\n"
     ]
    }
   ],
   "source": [
    "print(auc)\n",
    "print([m.train_auc for m in mods])\n",
    "print([m.model_cv.best_params_ for m in mods])\n",
    "print([m.model_cv.cv_results_['mean_test_score'] for m in mods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-36167965e296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_roc_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/data_projects/adfraud/adfraud/models.py\u001b[0m in \u001b[0;36mplot_roc_acc\u001b[0;34m(self, x_test, y_test)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpl' is not defined"
     ]
    }
   ],
   "source": [
    "mods[0].plot_roc_acc(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_ip_app_chan.plot_roc_acc(x_test)\n",
    "#model_ip_app_chan.train_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
